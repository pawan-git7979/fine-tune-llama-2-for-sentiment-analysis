{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1192499,"sourceType":"datasetVersion","datasetId":622510},{"sourceId":4295,"sourceType":"modelInstanceVersion","modelInstanceId":3090}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Fine-tune Llama 2 for Sentiment Analysis\n","metadata":{}},{"cell_type":"markdown","source":"## Installations and imports","metadata":{}},{"cell_type":"code","source":"!pip install -q -U \"torch==2.1.2\" tensorboard","metadata":{"execution":{"iopub.status.busy":"2024-03-15T06:29:51.137790Z","iopub.execute_input":"2024-03-15T06:29:51.138440Z","iopub.status.idle":"2024-03-15T06:30:02.791641Z","shell.execute_reply.started":"2024-03-15T06:29:51.138395Z","shell.execute_reply":"2024-03-15T06:30:02.790615Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install -q -U \"transformers==4.36.2\" \"datasets==2.16.1\" \"accelerate==0.26.1\" \"bitsandbytes==0.42.0\"","metadata":{"execution":{"iopub.status.busy":"2024-03-15T06:30:08.099930Z","iopub.execute_input":"2024-03-15T06:30:08.100312Z","iopub.status.idle":"2024-03-15T06:30:20.460220Z","shell.execute_reply.started":"2024-03-15T06:30:08.100272Z","shell.execute_reply":"2024-03-15T06:30:20.458965Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pip install -q -U git+https://github.com/huggingface/trl@a3c5b7178ac4f65569975efadc97db2f3749c65e\n!pip install -q -U git+https://github.com/huggingface/peft@4a1559582281fc3c9283892caea8ccef1d6f5a4f","metadata":{"execution":{"iopub.status.busy":"2024-03-15T06:30:38.741784Z","iopub.execute_input":"2024-03-15T06:30:38.742643Z","iopub.status.idle":"2024-03-15T06:31:32.882467Z","shell.execute_reply.started":"2024-03-15T06:30:38.742606Z","shell.execute_reply":"2024-03-15T06:31:32.881368Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"execution":{"iopub.status.busy":"2024-03-15T06:32:18.575283Z","iopub.execute_input":"2024-03-15T06:32:18.575929Z","iopub.status.idle":"2024-03-15T06:32:18.580577Z","shell.execute_reply.started":"2024-03-15T06:32:18.575891Z","shell.execute_reply":"2024-03-15T06:32:18.579668Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-03-15T06:32:18.581845Z","iopub.execute_input":"2024-03-15T06:32:18.582112Z","iopub.status.idle":"2024-03-15T06:32:18.602845Z","shell.execute_reply.started":"2024-03-15T06:32:18.582089Z","shell.execute_reply":"2024-03-15T06:32:18.601932Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\nimport bitsandbytes as bnb\nimport torch\nimport torch.nn as nn\nimport transformers\nfrom datasets import Dataset\nfrom peft import LoraConfig, PeftConfig\nfrom trl import SFTTrainer\nfrom trl import setup_chat_format\nfrom transformers import (AutoModelForCausalLM, \n                          AutoTokenizer, \n                          BitsAndBytesConfig, \n                          TrainingArguments, \n                          pipeline, \n                          logging)\nfrom sklearn.metrics import (accuracy_score, \n                             classification_report, \n                             confusion_matrix)\nfrom sklearn.model_selection import train_test_split","metadata":{"papermill":{"duration":14.485002,"end_time":"2023-10-16T11:00:18.917449","exception":false,"start_time":"2023-10-16T11:00:04.432447","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-15T06:32:18.604080Z","iopub.execute_input":"2024-03-15T06:32:18.604987Z","iopub.status.idle":"2024-03-15T06:32:18.612814Z","shell.execute_reply.started":"2024-03-15T06:32:18.604955Z","shell.execute_reply":"2024-03-15T06:32:18.612110Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(f\"pytorch version {torch.__version__}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-15T06:32:18.614199Z","iopub.execute_input":"2024-03-15T06:32:18.614458Z","iopub.status.idle":"2024-03-15T06:32:18.626391Z","shell.execute_reply.started":"2024-03-15T06:32:18.614436Z","shell.execute_reply":"2024-03-15T06:32:18.625416Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"pytorch version 2.1.2+cu121\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"working on {device}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-15T06:32:24.785274Z","iopub.execute_input":"2024-03-15T06:32:24.785637Z","iopub.status.idle":"2024-03-15T06:32:24.791527Z","shell.execute_reply.started":"2024-03-15T06:32:24.785610Z","shell.execute_reply":"2024-03-15T06:32:24.790538Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"working on cuda:0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Preparing the data and the core evaluation functions","metadata":{}},{"cell_type":"code","source":"filename = \"../input/sentiment-analysis-for-financial-news/all-data.csv\"\n\ndf = pd.read_csv(filename, \n                 names=[\"sentiment\", \"text\"],\n                 encoding=\"utf-8\", encoding_errors=\"replace\")\n\nX_train = list()\nX_test = list()\nfor sentiment in [\"positive\", \"neutral\", \"negative\"]:\n    train, test  = train_test_split(df[df.sentiment==sentiment], \n                                    train_size=300,\n                                    test_size=300, \n                                    random_state=42)\n    X_train.append(train)\n    X_test.append(test)\n\nX_train = pd.concat(X_train).sample(frac=1, random_state=10)\nX_test = pd.concat(X_test)\n\neval_idx = [idx for idx in df.index if idx not in list(train.index) + list(test.index)]\nX_eval = df[df.index.isin(eval_idx)]\nX_eval = (X_eval\n          .groupby('sentiment', group_keys=False)\n          .apply(lambda x: x.sample(n=50, random_state=10, replace=True)))\nX_train = X_train.reset_index(drop=True)\n\ndef generate_prompt(data_point):\n    return f\"\"\"\n            Analyze the sentiment of the news headline enclosed in square brackets, \n            determine if it is positive, neutral, or negative, and return the answer as \n            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\".\n\n            [{data_point[\"text\"]}] = {data_point[\"sentiment\"]}\n            \"\"\".strip()\n\ndef generate_test_prompt(data_point):\n    return f\"\"\"\n            Analyze the sentiment of the news headline enclosed in square brackets, \n            determine if it is positive, neutral, or negative, and return the answer as \n            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\".\n\n            [{data_point[\"text\"]}] = \"\"\".strip()\n\nX_train = pd.DataFrame(X_train.apply(generate_prompt, axis=1), \n                       columns=[\"text\"])\nX_eval = pd.DataFrame(X_eval.apply(generate_prompt, axis=1), \n                      columns=[\"text\"])\n\ny_true = X_test.sentiment\nX_test = pd.DataFrame(X_test.apply(generate_test_prompt, axis=1), columns=[\"text\"])\n\ntrain_data = Dataset.from_pandas(X_train)\neval_data = Dataset.from_pandas(X_eval)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T06:32:26.864751Z","iopub.execute_input":"2024-03-15T06:32:26.865627Z","iopub.status.idle":"2024-03-15T06:32:27.407417Z","shell.execute_reply.started":"2024-03-15T06:32:26.865592Z","shell.execute_reply":"2024-03-15T06:32:27.406614Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def evaluate(y_true, y_pred):\n    labels = ['positive', 'neutral', 'negative']\n    mapping = {'positive': 2, 'neutral': 1, 'none':1, 'negative': 0}\n    def map_func(x):\n        return mapping.get(x, 1)\n    \n    y_true = np.vectorize(map_func)(y_true)\n    y_pred = np.vectorize(map_func)(y_pred)\n    \n    # Calculate accuracy\n    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n    print(f'Accuracy: {accuracy:.3f}')\n    \n    # Generate accuracy report\n    unique_labels = set(y_true)  # Get unique labels\n    \n    for label in unique_labels:\n        label_indices = [i for i in range(len(y_true)) \n                         if y_true[i] == label]\n        label_y_true = [y_true[i] for i in label_indices]\n        label_y_pred = [y_pred[i] for i in label_indices]\n        accuracy = accuracy_score(label_y_true, label_y_pred)\n        print(f'Accuracy for label {label}: {accuracy:.3f}')\n        \n    # Generate classification report\n    class_report = classification_report(y_true=y_true, y_pred=y_pred)\n    print('\\nClassification Report:')\n    print(class_report)\n    \n    # Generate confusion matrix\n    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0, 1, 2])\n    print('\\nConfusion Matrix:')\n    print(conf_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T06:32:28.410344Z","iopub.execute_input":"2024-03-15T06:32:28.411255Z","iopub.status.idle":"2024-03-15T06:32:28.420581Z","shell.execute_reply.started":"2024-03-15T06:32:28.411209Z","shell.execute_reply":"2024-03-15T06:32:28.419571Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Testing the model without fine-tuning","metadata":{}},{"cell_type":"code","source":"model_name = \"../input/llama-2/pytorch/7b-hf/1\"\n\ncompute_dtype = getattr(torch, \"float16\")\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True, \n    bnb_4bit_quant_type=\"nf4\", \n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=True,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    device_map=device,\n    torch_dtype=compute_dtype,\n    quantization_config=bnb_config, \n)\n\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\ntokenizer = AutoTokenizer.from_pretrained(model_name, \n                                          trust_remote_code=True,\n                                         )\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"\n\nmodel, tokenizer = setup_chat_format(model, tokenizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(test, model, tokenizer):\n    y_pred = []\n    for i in tqdm(range(len(X_test))):\n        prompt = X_test.iloc[i][\"text\"]\n        pipe = pipeline(task=\"text-generation\", \n                        model=model, \n                        tokenizer=tokenizer, \n                        max_new_tokens = 1, \n                        temperature = 0.0,\n                       )\n        result = pipe(prompt)\n        answer = result[0]['generated_text'].split(\"=\")[-1]\n        if \"positive\" in answer:\n            y_pred.append(\"positive\")\n        elif \"negative\" in answer:\n            y_pred.append(\"negative\")\n        elif \"neutral\" in answer:\n            y_pred.append(\"neutral\")\n        else:\n            y_pred.append(\"none\")\n    return y_pred","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:25:52.447624Z","iopub.execute_input":"2024-02-19T15:25:52.447931Z","iopub.status.idle":"2024-02-19T15:25:52.455064Z","shell.execute_reply.started":"2024-02-19T15:25:52.447907Z","shell.execute_reply":"2024-02-19T15:25:52.454108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = predict(test, model, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:25:52.45609Z","iopub.execute_input":"2024-02-19T15:25:52.456432Z","iopub.status.idle":"2024-02-19T15:31:20.605915Z","shell.execute_reply.started":"2024-02-19T15:25:52.456403Z","shell.execute_reply":"2024-02-19T15:31:20.604946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:31:20.607384Z","iopub.execute_input":"2024-02-19T15:31:20.608098Z","iopub.status.idle":"2024-02-19T15:31:20.631677Z","shell.execute_reply.started":"2024-02-19T15:31:20.608062Z","shell.execute_reply":"2024-02-19T15:31:20.630744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fine-tuning","metadata":{}},{"cell_type":"code","source":"output_dir=\"trained_weigths\"\n\npeft_config = LoraConfig(\n        lora_alpha=16, \n        lora_dropout=0.1,\n        r=64,\n        bias=\"none\",\n        target_modules=\"all-linear\",\n        task_type=\"CAUSAL_LM\",\n)\n\ntraining_arguments = TrainingArguments(\n    output_dir=output_dir,                    # directory to save and repository id\n    num_train_epochs=3,                       # number of training epochs\n    per_device_train_batch_size=1,            # batch size per device during training\n    gradient_accumulation_steps=8,            # number of steps before performing a backward/update pass\n    gradient_checkpointing=True,              # use gradient checkpointing to save memory\n    optim=\"paged_adamw_32bit\",\n    save_steps=0,\n    logging_steps=25,                         # log every 10 steps\n    learning_rate=2e-4,                       # learning rate, based on QLoRA paper\n    weight_decay=0.001,\n    fp16=True,\n    bf16=False,\n    max_grad_norm=0.3,                        # max gradient norm based on QLoRA paper\n    max_steps=-1,\n    warmup_ratio=0.03,                        # warmup ratio based on QLoRA paper\n    group_by_length=True,\n    lr_scheduler_type=\"cosine\",               # use cosine learning rate scheduler\n    report_to=\"tensorboard\",                  # report metrics to tensorboard\n    evaluation_strategy=\"epoch\"               # save checkpoint every epoch\n)\n\ntrainer = SFTTrainer(\n    model=model,\n    args=training_arguments,\n    train_dataset=train_data,\n    eval_dataset=eval_data,\n    peft_config=peft_config,\n    dataset_text_field=\"text\",\n    tokenizer=tokenizer,\n    max_seq_length=1024,\n    packing=False,\n    dataset_kwargs={\n        \"add_special_tokens\": False,\n        \"append_concat_token\": False,\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:31:20.632722Z","iopub.execute_input":"2024-02-19T15:31:20.63299Z","iopub.status.idle":"2024-02-19T15:31:23.479593Z","shell.execute_reply.started":"2024-02-19T15:31:20.632967Z","shell.execute_reply":"2024-02-19T15:31:23.478212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:31:23.480899Z","iopub.execute_input":"2024-02-19T15:31:23.481197Z","iopub.status.idle":"2024-02-19T15:33:05.89364Z","shell.execute_reply.started":"2024-02-19T15:31:23.481164Z","shell.execute_reply":"2024-02-19T15:33:05.892738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save trained model and tokenizer\ntrainer.save_model()\ntokenizer.save_pretrained(output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:33:05.894879Z","iopub.execute_input":"2024-02-19T15:33:05.895578Z","iopub.status.idle":"2024-02-19T15:33:09.878108Z","shell.execute_reply.started":"2024-02-19T15:33:05.895541Z","shell.execute_reply":"2024-02-19T15:33:09.877301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext tensorboard\n%tensorboard --logdir logs/runs","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:33:09.879196Z","iopub.execute_input":"2024-02-19T15:33:09.879809Z","iopub.status.idle":"2024-02-19T15:33:16.414572Z","shell.execute_reply.started":"2024-02-19T15:33:09.879781Z","shell.execute_reply":"2024-02-19T15:33:16.413594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving model to disk for later usage","metadata":{}},{"cell_type":"markdown","source":"Before proceeding, we first remove the previous model and clean up the memory from various objects we won't use anymore.","metadata":{}},{"cell_type":"code","source":"import gc\n\ndel [model, tokenizer, peft_config, trainer, train_data, eval_data, bnb_config, training_arguments]\ndel [df, X_train, X_eval]\ndel [TrainingArguments, SFTTrainer, LoraConfig, BitsAndBytesConfig]","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:33:16.415701Z","iopub.execute_input":"2024-02-19T15:33:16.415998Z","iopub.status.idle":"2024-02-19T15:33:16.423616Z","shell.execute_reply.started":"2024-02-19T15:33:16.415972Z","shell.execute_reply":"2024-02-19T15:33:16.422854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for _ in range(100):\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:33:16.424703Z","iopub.execute_input":"2024-02-19T15:33:16.424959Z","iopub.status.idle":"2024-02-19T15:33:46.018557Z","shell.execute_reply.started":"2024-02-19T15:33:16.424936Z","shell.execute_reply":"2024-02-19T15:33:46.017451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:33:46.023367Z","iopub.execute_input":"2024-02-19T15:33:46.023673Z","iopub.status.idle":"2024-02-19T15:33:47.047959Z","shell.execute_reply.started":"2024-02-19T15:33:46.023647Z","shell.execute_reply":"2024-02-19T15:33:47.046745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from peft import AutoPeftModelForCausalLM\n\nfinetuned_model = \"./trained_weigths/\"\ncompute_dtype = getattr(torch, \"float16\")\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/llama-2/pytorch/7b-hf/1\")\n\nmodel = AutoPeftModelForCausalLM.from_pretrained(\n     finetuned_model,\n     torch_dtype=compute_dtype,\n     return_dict=False,\n     low_cpu_mem_usage=True,\n     device_map=device,\n)\n\nmerged_model = model.merge_and_unload()\nmerged_model.save_pretrained(\"./merged_model\",safe_serialization=True, max_shard_size=\"2GB\")\ntokenizer.save_pretrained(\"./merged_model\")","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:33:47.049597Z","iopub.execute_input":"2024-02-19T15:33:47.049911Z","iopub.status.idle":"2024-02-19T15:34:49.641179Z","shell.execute_reply.started":"2024-02-19T15:33:47.049882Z","shell.execute_reply":"2024-02-19T15:34:49.640347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"y_pred = predict(test, merged_model, tokenizer)\nevaluate(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T15:34:49.643414Z","iopub.execute_input":"2024-02-19T15:34:49.644055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluation = pd.DataFrame({'text': X_test[\"text\"], \n                           'y_true':y_true, \n                           'y_pred': y_pred},\n                         )\nevaluation.to_csv(\"test_predictions.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here are the results of the baseline model:\n\nAccuracy: 0.623\nAccuracy for label 0: 0.620\nAccuracy for label 1: 0.590\nAccuracy for label 2: 0.660\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.79      0.62      0.69       300\n           1       0.61      0.59      0.60       300\n           2       0.53      0.66      0.59       300\n\n    accuracy                           0.62       900\n   macro avg       0.64      0.62      0.63       900\nweighted avg       0.64      0.62      0.63       900\n\n\nConfusion Matrix:\n\n[[186  39  75]\\\n [ 23 177 100]\\\n [ 27  75 198]]\n ","metadata":{}}]}